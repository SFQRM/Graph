//Running date:2019.10.30

(gcn) C:\Users\zang>d:

(gcn) D:\>cd D:\code\Python\workplace\gcn

(gcn) D:\code\Python\workplace\gcn>python setup.py install
running install
running bdist_egg
running egg_info
creating gcn.egg-info
writing gcn.egg-info\PKG-INFO
writing dependency_links to gcn.egg-info\dependency_links.txt
writing requirements to gcn.egg-info\requires.txt
writing top-level names to gcn.egg-info\top_level.txt
writing manifest file 'gcn.egg-info\SOURCES.txt'
reading manifest file 'gcn.egg-info\SOURCES.txt'
writing manifest file 'gcn.egg-info\SOURCES.txt'
installing library code to build\bdist.win-amd64\egg
running install_lib
running build_py
creating build
creating build\lib
creating build\lib\gcn
copying gcn\inits.py -> build\lib\gcn
copying gcn\layers.py -> build\lib\gcn
copying gcn\metrics.py -> build\lib\gcn
copying gcn\models.py -> build\lib\gcn
copying gcn\train.py -> build\lib\gcn
copying gcn\utils.py -> build\lib\gcn
copying gcn\__init__.py -> build\lib\gcn
creating build\bdist.win-amd64
creating build\bdist.win-amd64\egg
creating build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\inits.py -> build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\layers.py -> build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\metrics.py -> build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\models.py -> build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\train.py -> build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\utils.py -> build\bdist.win-amd64\egg\gcn
copying build\lib\gcn\__init__.py -> build\bdist.win-amd64\egg\gcn
byte-compiling build\bdist.win-amd64\egg\gcn\inits.py to inits.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\gcn\layers.py to layers.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\gcn\metrics.py to metrics.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\gcn\models.py to models.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\gcn\train.py to train.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\gcn\utils.py to utils.cpython-36.pyc
byte-compiling build\bdist.win-amd64\egg\gcn\__init__.py to __init__.cpython-36.pyc
creating build\bdist.win-amd64\egg\EGG-INFO
copying gcn.egg-info\PKG-INFO -> build\bdist.win-amd64\egg\EGG-INFO
copying gcn.egg-info\SOURCES.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying gcn.egg-info\dependency_links.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying gcn.egg-info\requires.txt -> build\bdist.win-amd64\egg\EGG-INFO
copying gcn.egg-info\top_level.txt -> build\bdist.win-amd64\egg\EGG-INFO
zip_safe flag not set; analyzing archive contents...
creating dist
creating 'dist\gcn-1.0-py3.6.egg' and adding 'build\bdist.win-amd64\egg' to it
removing 'build\bdist.win-amd64\egg' (and everything under it)
Processing gcn-1.0-py3.6.egg
Copying gcn-1.0-py3.6.egg to c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Adding gcn 1.0 to easy-install.pth file

Installed c:\users\zang\anaconda3\envs\gcn\lib\site-packages\gcn-1.0-py3.6.egg
Processing dependencies for gcn==1.0
Searching for scipy==1.1.0
Best match: scipy 1.1.0
Adding scipy 1.1.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for networkx==2.2
Best match: networkx 2.2
Adding networkx 2.2 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for tensorflow==1.13.1
Best match: tensorflow 1.13.1
Adding tensorflow 1.13.1 to easy-install.pth file
Installing freeze_graph-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing freeze_graph.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing saved_model_cli-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing saved_model_cli.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tensorboard-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tensorboard.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tf_upgrade_v2-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tf_upgrade_v2.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tflite_convert-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tflite_convert.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing toco-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing toco.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing toco_from_protos-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing toco_from_protos.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for numpy==1.15.4
Best match: numpy 1.15.4
Adding numpy 1.15.4 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for decorator==4.4.0
Best match: decorator 4.4.0
Adding decorator 4.4.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for six==1.12.0
Best match: six 1.12.0
Adding six 1.12.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for astor==0.8.0
Best match: astor 0.8.0
Adding astor 0.8.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for absl-py==0.8.0
Best match: absl-py 0.8.0
Adding absl-py 0.8.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for gast==0.3.2
Best match: gast 0.3.2
Adding gast 0.3.2 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for grpcio==1.16.1
Best match: grpcio 1.16.1
Adding grpcio 1.16.1 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for wheel==0.33.6
Best match: wheel 0.33.6
Adding wheel 0.33.6 to easy-install.pth file
Installing wheel-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing wheel.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for tensorboard==1.13.1
Best match: tensorboard 1.13.1
Adding tensorboard 1.13.1 to easy-install.pth file
Installing tensorboard-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing tensorboard.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for termcolor==1.1.0
Best match: termcolor 1.1.0
Adding termcolor 1.1.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for protobuf==3.9.2
Best match: protobuf 3.9.2
Adding protobuf 3.9.2 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for Keras-Applications==1.0.8
Best match: Keras-Applications 1.0.8
Adding Keras-Applications 1.0.8 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for tensorflow-estimator==1.13.0
Best match: tensorflow-estimator 1.13.0
Adding tensorflow-estimator 1.13.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for Keras-Preprocessing==1.1.0
Best match: Keras-Preprocessing 1.1.0
Adding Keras-Preprocessing 1.1.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for Markdown==3.1.1
Best match: Markdown 3.1.1
Adding Markdown 3.1.1 to easy-install.pth file
Installing markdown_py-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing markdown_py.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for Werkzeug==0.16.0
Best match: Werkzeug 0.16.0
Adding Werkzeug 0.16.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for setuptools==40.6.3
Best match: setuptools 40.6.3
Adding setuptools 40.6.3 to easy-install.pth file
Installing easy_install-script.py script to C:\Users\zang\Anaconda3\envs\gcn\Scripts
Installing easy_install.exe script to C:\Users\zang\Anaconda3\envs\gcn\Scripts

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Searching for h5py==2.9.0
Best match: h5py 2.9.0
Adding h5py 2.9.0 to easy-install.pth file

Using c:\users\zang\anaconda3\envs\gcn\lib\site-packages
Finished processing dependencies for gcn==1.0

(gcn) D:\code\Python\workplace\gcn>cd gcn

(gcn) D:\code\Python\workplace\gcn\gcn>python train.py
WARNING:tensorflow:From C:\Users\zang\Anaconda3\envs\gcn\lib\site-packages\tensorflow\python\framework\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From C:\Users\zang\Anaconda3\envs\gcn\lib\site-packages\gcn-1.0-py3.6.egg\gcn\layers.py:170: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From C:\Users\zang\Anaconda3\envs\gcn\lib\site-packages\gcn-1.0-py3.6.egg\gcn\metrics.py:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

WARNING:tensorflow:From C:\Users\zang\Anaconda3\envs\gcn\lib\site-packages\tensorflow\python\ops\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-10-30 12:14:20.504076: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-10-30 12:14:20.555822: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.
Epoch: 0001 train_loss= 1.95461 train_acc= 0.07857 val_loss= 1.95068 val_acc= 0.17600 time= 0.37778
Epoch: 0002 train_loss= 1.94861 train_acc= 0.25714 val_loss= 1.94722 val_acc= 0.32400 time= 0.06896
Epoch: 0003 train_loss= 1.94277 train_acc= 0.50000 val_loss= 1.94340 val_acc= 0.43400 time= 0.06996
Epoch: 0004 train_loss= 1.93624 train_acc= 0.55714 val_loss= 1.93984 val_acc= 0.45000 time= 0.06896
Epoch: 0005 train_loss= 1.92757 train_acc= 0.67857 val_loss= 1.93628 val_acc= 0.44200 time= 0.07096
Epoch: 0006 train_loss= 1.92056 train_acc= 0.66429 val_loss= 1.93239 val_acc= 0.44600 time= 0.06796
Epoch: 0007 train_loss= 1.91186 train_acc= 0.64286 val_loss= 1.92828 val_acc= 0.44400 time= 0.06896
Epoch: 0008 train_loss= 1.90454 train_acc= 0.62857 val_loss= 1.92421 val_acc= 0.44200 time= 0.06996
Epoch: 0009 train_loss= 1.89406 train_acc= 0.70000 val_loss= 1.92011 val_acc= 0.45800 time= 0.06896
Epoch: 0010 train_loss= 1.88493 train_acc= 0.70000 val_loss= 1.91599 val_acc= 0.47800 time= 0.06996
Epoch: 0011 train_loss= 1.87616 train_acc= 0.74286 val_loss= 1.91180 val_acc= 0.51000 time= 0.06896
Epoch: 0012 train_loss= 1.87072 train_acc= 0.73571 val_loss= 1.90748 val_acc= 0.52800 time= 0.06796
Epoch: 0013 train_loss= 1.86251 train_acc= 0.70714 val_loss= 1.90315 val_acc= 0.55200 time= 0.06796
Epoch: 0014 train_loss= 1.84735 train_acc= 0.70714 val_loss= 1.89871 val_acc= 0.56400 time= 0.06996
Epoch: 0015 train_loss= 1.83780 train_acc= 0.72857 val_loss= 1.89422 val_acc= 0.57600 time= 0.06796
Epoch: 0016 train_loss= 1.81915 train_acc= 0.77143 val_loss= 1.88969 val_acc= 0.57800 time= 0.06896
Epoch: 0017 train_loss= 1.81948 train_acc= 0.75714 val_loss= 1.88508 val_acc= 0.59000 time= 0.06796
Epoch: 0018 train_loss= 1.81147 train_acc= 0.77143 val_loss= 1.88036 val_acc= 0.59000 time= 0.06896
Epoch: 0019 train_loss= 1.78988 train_acc= 0.80000 val_loss= 1.87534 val_acc= 0.59800 time= 0.06796
Epoch: 0020 train_loss= 1.78313 train_acc= 0.76429 val_loss= 1.87020 val_acc= 0.60400 time= 0.06896
Epoch: 0021 train_loss= 1.76766 train_acc= 0.80000 val_loss= 1.86487 val_acc= 0.60600 time= 0.06896
Epoch: 0022 train_loss= 1.74921 train_acc= 0.80714 val_loss= 1.85943 val_acc= 0.61000 time= 0.06996
Epoch: 0023 train_loss= 1.74168 train_acc= 0.75000 val_loss= 1.85380 val_acc= 0.61400 time= 0.06796
Epoch: 0024 train_loss= 1.72814 train_acc= 0.77143 val_loss= 1.84797 val_acc= 0.61400 time= 0.06896
Epoch: 0025 train_loss= 1.71721 train_acc= 0.78571 val_loss= 1.84191 val_acc= 0.61400 time= 0.06796
Epoch: 0026 train_loss= 1.70792 train_acc= 0.82143 val_loss= 1.83568 val_acc= 0.62600 time= 0.06796
Epoch: 0027 train_loss= 1.68943 train_acc= 0.81429 val_loss= 1.82938 val_acc= 0.63000 time= 0.06896
Epoch: 0028 train_loss= 1.67868 train_acc= 0.77143 val_loss= 1.82284 val_acc= 0.64400 time= 0.06896
Epoch: 0029 train_loss= 1.66631 train_acc= 0.81429 val_loss= 1.81601 val_acc= 0.65200 time= 0.06796
Epoch: 0030 train_loss= 1.67101 train_acc= 0.80000 val_loss= 1.80893 val_acc= 0.66200 time= 0.06796
Epoch: 0031 train_loss= 1.61723 train_acc= 0.81429 val_loss= 1.80165 val_acc= 0.66600 time= 0.06896
Epoch: 0032 train_loss= 1.64374 train_acc= 0.80000 val_loss= 1.79417 val_acc= 0.66400 time= 0.06896
Epoch: 0033 train_loss= 1.60085 train_acc= 0.85000 val_loss= 1.78656 val_acc= 0.67600 time= 0.06796
Epoch: 0034 train_loss= 1.59783 train_acc= 0.82857 val_loss= 1.77900 val_acc= 0.67600 time= 0.06796
Epoch: 0035 train_loss= 1.56746 train_acc= 0.85000 val_loss= 1.77145 val_acc= 0.68200 time= 0.06896
Epoch: 0036 train_loss= 1.57142 train_acc= 0.85714 val_loss= 1.76377 val_acc= 0.68400 time= 0.06896
Epoch: 0037 train_loss= 1.53495 train_acc= 0.87857 val_loss= 1.75596 val_acc= 0.69000 time= 0.06796
Epoch: 0038 train_loss= 1.52689 train_acc= 0.85000 val_loss= 1.74782 val_acc= 0.69600 time= 0.06896
Epoch: 0039 train_loss= 1.51676 train_acc= 0.85714 val_loss= 1.73937 val_acc= 0.70800 time= 0.06896
Epoch: 0040 train_loss= 1.49229 train_acc= 0.82143 val_loss= 1.73085 val_acc= 0.70800 time= 0.06896
Epoch: 0041 train_loss= 1.47217 train_acc= 0.87143 val_loss= 1.72235 val_acc= 0.71000 time= 0.06896
Epoch: 0042 train_loss= 1.46521 train_acc= 0.88571 val_loss= 1.71376 val_acc= 0.71400 time= 0.06796
Epoch: 0043 train_loss= 1.48915 train_acc= 0.85000 val_loss= 1.70508 val_acc= 0.71800 time= 0.06796
Epoch: 0044 train_loss= 1.42744 train_acc= 0.87857 val_loss= 1.69643 val_acc= 0.72200 time= 0.06896
Epoch: 0045 train_loss= 1.44664 train_acc= 0.85714 val_loss= 1.68788 val_acc= 0.72400 time= 0.06796
Epoch: 0046 train_loss= 1.38420 train_acc= 0.89286 val_loss= 1.67896 val_acc= 0.72800 time= 0.06896
Epoch: 0047 train_loss= 1.41269 train_acc= 0.86429 val_loss= 1.66994 val_acc= 0.73200 time= 0.06821
Epoch: 0048 train_loss= 1.36044 train_acc= 0.89286 val_loss= 1.66085 val_acc= 0.73600 time= 0.06896
Epoch: 0049 train_loss= 1.37246 train_acc= 0.87143 val_loss= 1.65166 val_acc= 0.74400 time= 0.06796
Epoch: 0050 train_loss= 1.34976 train_acc= 0.84286 val_loss= 1.64231 val_acc= 0.74600 time= 0.06896
Epoch: 0051 train_loss= 1.30979 train_acc= 0.88571 val_loss= 1.63305 val_acc= 0.74800 time= 0.06896
Epoch: 0052 train_loss= 1.34911 train_acc= 0.85714 val_loss= 1.62362 val_acc= 0.75000 time= 0.06996
Epoch: 0053 train_loss= 1.32759 train_acc= 0.88571 val_loss= 1.61426 val_acc= 0.75200 time= 0.06896
Epoch: 0054 train_loss= 1.28248 train_acc= 0.90714 val_loss= 1.60485 val_acc= 0.75400 time= 0.06896
Epoch: 0055 train_loss= 1.29519 train_acc= 0.88571 val_loss= 1.59545 val_acc= 0.75600 time= 0.06896
Epoch: 0056 train_loss= 1.28051 train_acc= 0.85000 val_loss= 1.58634 val_acc= 0.76400 time= 0.06896
Epoch: 0057 train_loss= 1.23875 train_acc= 0.93571 val_loss= 1.57727 val_acc= 0.76400 time= 0.06896
Epoch: 0058 train_loss= 1.23108 train_acc= 0.92143 val_loss= 1.56772 val_acc= 0.77000 time= 0.06896
Epoch: 0059 train_loss= 1.22798 train_acc= 0.89286 val_loss= 1.55801 val_acc= 0.77400 time= 0.06896
Epoch: 0060 train_loss= 1.22555 train_acc= 0.92857 val_loss= 1.54826 val_acc= 0.77400 time= 0.06796
Epoch: 0061 train_loss= 1.20502 train_acc= 0.90000 val_loss= 1.53905 val_acc= 0.77400 time= 0.06996
Epoch: 0062 train_loss= 1.20688 train_acc= 0.90000 val_loss= 1.53007 val_acc= 0.77400 time= 0.06896
Epoch: 0063 train_loss= 1.12479 train_acc= 0.92143 val_loss= 1.52103 val_acc= 0.77400 time= 0.06896
Epoch: 0064 train_loss= 1.15719 train_acc= 0.94286 val_loss= 1.51218 val_acc= 0.77600 time= 0.06896
Epoch: 0065 train_loss= 1.11420 train_acc= 0.91429 val_loss= 1.50361 val_acc= 0.77800 time= 0.06896
Epoch: 0066 train_loss= 1.12602 train_acc= 0.92857 val_loss= 1.49483 val_acc= 0.77800 time= 0.06896
Epoch: 0067 train_loss= 1.10880 train_acc= 0.94286 val_loss= 1.48608 val_acc= 0.77800 time= 0.06896
Epoch: 0068 train_loss= 1.14477 train_acc= 0.92143 val_loss= 1.47759 val_acc= 0.77800 time= 0.06796
Epoch: 0069 train_loss= 1.10611 train_acc= 0.92857 val_loss= 1.46927 val_acc= 0.77800 time= 0.06896
Epoch: 0070 train_loss= 1.12255 train_acc= 0.92143 val_loss= 1.46145 val_acc= 0.77600 time= 0.06896
Epoch: 0071 train_loss= 1.07954 train_acc= 0.89286 val_loss= 1.45367 val_acc= 0.77600 time= 0.06896
Epoch: 0072 train_loss= 1.06249 train_acc= 0.93571 val_loss= 1.44593 val_acc= 0.77600 time= 0.06796
Epoch: 0073 train_loss= 1.07659 train_acc= 0.92143 val_loss= 1.43838 val_acc= 0.77400 time= 0.06996
Epoch: 0074 train_loss= 1.07699 train_acc= 0.92857 val_loss= 1.43076 val_acc= 0.77400 time= 0.06896
Epoch: 0075 train_loss= 1.04676 train_acc= 0.91429 val_loss= 1.42319 val_acc= 0.77400 time= 0.06896
Epoch: 0076 train_loss= 1.00799 train_acc= 0.93571 val_loss= 1.41567 val_acc= 0.77600 time= 0.06896
Epoch: 0077 train_loss= 1.01398 train_acc= 0.94286 val_loss= 1.40805 val_acc= 0.77800 time= 0.06896
Epoch: 0078 train_loss= 1.02109 train_acc= 0.93571 val_loss= 1.40074 val_acc= 0.77800 time= 0.06896
Epoch: 0079 train_loss= 1.03909 train_acc= 0.93571 val_loss= 1.39384 val_acc= 0.77800 time= 0.06996
Epoch: 0080 train_loss= 1.00015 train_acc= 0.97143 val_loss= 1.38720 val_acc= 0.77600 time= 0.06896
Epoch: 0081 train_loss= 1.00614 train_acc= 0.90714 val_loss= 1.38084 val_acc= 0.77600 time= 0.06896
Epoch: 0082 train_loss= 0.99936 train_acc= 0.92143 val_loss= 1.37477 val_acc= 0.77600 time= 0.06996
Epoch: 0083 train_loss= 1.00355 train_acc= 0.90000 val_loss= 1.36866 val_acc= 0.77600 time= 0.06896
Epoch: 0084 train_loss= 0.97826 train_acc= 0.92143 val_loss= 1.36263 val_acc= 0.77600 time= 0.06796
Epoch: 0085 train_loss= 0.96908 train_acc= 0.93571 val_loss= 1.35691 val_acc= 0.77600 time= 0.06796
Epoch: 0086 train_loss= 0.96762 train_acc= 0.92143 val_loss= 1.35139 val_acc= 0.77600 time= 0.06996
Epoch: 0087 train_loss= 0.97634 train_acc= 0.93571 val_loss= 1.34582 val_acc= 0.77600 time= 0.06896
Epoch: 0088 train_loss= 0.92449 train_acc= 0.92857 val_loss= 1.33998 val_acc= 0.77600 time= 0.06896
Epoch: 0089 train_loss= 0.93838 train_acc= 0.92857 val_loss= 1.33409 val_acc= 0.77400 time= 0.06896
Epoch: 0090 train_loss= 0.91158 train_acc= 0.92857 val_loss= 1.32840 val_acc= 0.77600 time= 0.06996
Epoch: 0091 train_loss= 0.93719 train_acc= 0.94286 val_loss= 1.32327 val_acc= 0.77600 time= 0.06796
Epoch: 0092 train_loss= 0.94949 train_acc= 0.95714 val_loss= 1.31862 val_acc= 0.77600 time= 0.06896
Epoch: 0093 train_loss= 0.85234 train_acc= 0.95000 val_loss= 1.31410 val_acc= 0.77400 time= 0.06796
Epoch: 0094 train_loss= 0.86402 train_acc= 0.93571 val_loss= 1.30961 val_acc= 0.77400 time= 0.06896
Epoch: 0095 train_loss= 0.89524 train_acc= 0.95000 val_loss= 1.30513 val_acc= 0.77400 time= 0.06996
Epoch: 0096 train_loss= 0.87066 train_acc= 0.93571 val_loss= 1.30005 val_acc= 0.77400 time= 0.06896
Epoch: 0097 train_loss= 0.92863 train_acc= 0.91429 val_loss= 1.29527 val_acc= 0.77400 time= 0.06896
Epoch: 0098 train_loss= 0.92609 train_acc= 0.87857 val_loss= 1.29066 val_acc= 0.77400 time= 0.06896
Epoch: 0099 train_loss= 0.89037 train_acc= 0.91429 val_loss= 1.28547 val_acc= 0.77600 time= 0.06996
Epoch: 0100 train_loss= 0.88579 train_acc= 0.92143 val_loss= 1.28054 val_acc= 0.77800 time= 0.06896
Epoch: 0101 train_loss= 0.86651 train_acc= 0.91429 val_loss= 1.27569 val_acc= 0.77800 time= 0.06896
Epoch: 0102 train_loss= 0.77166 train_acc= 0.96429 val_loss= 1.27073 val_acc= 0.78000 time= 0.06896
Epoch: 0103 train_loss= 0.82397 train_acc= 0.95714 val_loss= 1.26585 val_acc= 0.77800 time= 0.06896
Epoch: 0104 train_loss= 0.86391 train_acc= 0.95714 val_loss= 1.26094 val_acc= 0.77800 time= 0.06896
Epoch: 0105 train_loss= 0.86808 train_acc= 0.94286 val_loss= 1.25597 val_acc= 0.77800 time= 0.06996
Epoch: 0106 train_loss= 0.84248 train_acc= 0.95000 val_loss= 1.25098 val_acc= 0.77800 time= 0.06796
Epoch: 0107 train_loss= 0.84908 train_acc= 0.91429 val_loss= 1.24640 val_acc= 0.77800 time= 0.06896
Epoch: 0108 train_loss= 0.86796 train_acc= 0.92143 val_loss= 1.24264 val_acc= 0.77800 time= 0.06996
Epoch: 0109 train_loss= 0.86809 train_acc= 0.95000 val_loss= 1.23947 val_acc= 0.77800 time= 0.06896
Epoch: 0110 train_loss= 0.77492 train_acc= 0.97143 val_loss= 1.23592 val_acc= 0.77600 time= 0.06896
Epoch: 0111 train_loss= 0.84524 train_acc= 0.95000 val_loss= 1.23276 val_acc= 0.77600 time= 0.06896
Epoch: 0112 train_loss= 0.82436 train_acc= 0.95714 val_loss= 1.22940 val_acc= 0.77800 time= 0.06996
Epoch: 0113 train_loss= 0.83012 train_acc= 0.95000 val_loss= 1.22622 val_acc= 0.78000 time= 0.06896
Epoch: 0114 train_loss= 0.80895 train_acc= 0.92857 val_loss= 1.22306 val_acc= 0.78000 time= 0.06996
Epoch: 0115 train_loss= 0.80211 train_acc= 0.95000 val_loss= 1.21955 val_acc= 0.78400 time= 0.06896
Epoch: 0116 train_loss= 0.78301 train_acc= 0.96429 val_loss= 1.21619 val_acc= 0.78400 time= 0.06996
Epoch: 0117 train_loss= 0.78213 train_acc= 0.97143 val_loss= 1.21326 val_acc= 0.78600 time= 0.06896
Epoch: 0118 train_loss= 0.80806 train_acc= 0.94286 val_loss= 1.21037 val_acc= 0.78200 time= 0.06796
Epoch: 0119 train_loss= 0.76637 train_acc= 0.95714 val_loss= 1.20691 val_acc= 0.78000 time= 0.06796
Epoch: 0120 train_loss= 0.78262 train_acc= 0.94286 val_loss= 1.20380 val_acc= 0.78200 time= 0.06896
Epoch: 0121 train_loss= 0.76158 train_acc= 0.93571 val_loss= 1.20087 val_acc= 0.78200 time= 0.06896
Epoch: 0122 train_loss= 0.77224 train_acc= 0.97143 val_loss= 1.19766 val_acc= 0.78200 time= 0.06896
Epoch: 0123 train_loss= 0.72653 train_acc= 0.99286 val_loss= 1.19419 val_acc= 0.78200 time= 0.06896
Epoch: 0124 train_loss= 0.78579 train_acc= 0.95000 val_loss= 1.19064 val_acc= 0.78000 time= 0.06996
Epoch: 0125 train_loss= 0.75468 train_acc= 0.95714 val_loss= 1.18695 val_acc= 0.78000 time= 0.06796
Epoch: 0126 train_loss= 0.75187 train_acc= 0.95714 val_loss= 1.18305 val_acc= 0.77800 time= 0.06896
Epoch: 0127 train_loss= 0.78744 train_acc= 0.94286 val_loss= 1.17976 val_acc= 0.77600 time= 0.06896
Epoch: 0128 train_loss= 0.75010 train_acc= 0.94286 val_loss= 1.17618 val_acc= 0.77600 time= 0.06896
Epoch: 0129 train_loss= 0.70196 train_acc= 0.97143 val_loss= 1.17235 val_acc= 0.77600 time= 0.06896
Epoch: 0130 train_loss= 0.77875 train_acc= 0.94286 val_loss= 1.16897 val_acc= 0.77600 time= 0.06896
Epoch: 0131 train_loss= 0.73701 train_acc= 0.97143 val_loss= 1.16613 val_acc= 0.77600 time= 0.06896
Epoch: 0132 train_loss= 0.70017 train_acc= 0.95000 val_loss= 1.16354 val_acc= 0.77800 time= 0.06896
Epoch: 0133 train_loss= 0.71598 train_acc= 0.97857 val_loss= 1.16143 val_acc= 0.77800 time= 0.06996
Epoch: 0134 train_loss= 0.79477 train_acc= 0.94286 val_loss= 1.15989 val_acc= 0.77800 time= 0.06896
Epoch: 0135 train_loss= 0.72684 train_acc= 0.95714 val_loss= 1.15848 val_acc= 0.77800 time= 0.06896
Epoch: 0136 train_loss= 0.72221 train_acc= 0.95000 val_loss= 1.15722 val_acc= 0.77800 time= 0.06996
Epoch: 0137 train_loss= 0.76138 train_acc= 0.95000 val_loss= 1.15601 val_acc= 0.77800 time= 0.06896
Epoch: 0138 train_loss= 0.71077 train_acc= 0.95000 val_loss= 1.15485 val_acc= 0.77800 time= 0.06896
Epoch: 0139 train_loss= 0.71587 train_acc= 0.95714 val_loss= 1.15350 val_acc= 0.77800 time= 0.06796
Epoch: 0140 train_loss= 0.70428 train_acc= 0.97857 val_loss= 1.15174 val_acc= 0.78000 time= 0.06796
Epoch: 0141 train_loss= 0.71417 train_acc= 0.95000 val_loss= 1.15027 val_acc= 0.77800 time= 0.06896
Epoch: 0142 train_loss= 0.69698 train_acc= 0.97143 val_loss= 1.14911 val_acc= 0.77800 time= 0.06896
Epoch: 0143 train_loss= 0.74747 train_acc= 0.92143 val_loss= 1.14783 val_acc= 0.77800 time= 0.06996
Epoch: 0144 train_loss= 0.75270 train_acc= 0.95714 val_loss= 1.14594 val_acc= 0.77800 time= 0.06896
Epoch: 0145 train_loss= 0.68286 train_acc= 0.95714 val_loss= 1.14391 val_acc= 0.77800 time= 0.06896
Epoch: 0146 train_loss= 0.73422 train_acc= 0.97857 val_loss= 1.14105 val_acc= 0.77800 time= 0.06996
Epoch: 0147 train_loss= 0.71266 train_acc= 0.93571 val_loss= 1.13823 val_acc= 0.77800 time= 0.06896
Epoch: 0148 train_loss= 0.68726 train_acc= 0.93571 val_loss= 1.13560 val_acc= 0.78200 time= 0.06996
Epoch: 0149 train_loss= 0.70256 train_acc= 0.98571 val_loss= 1.13302 val_acc= 0.78200 time= 0.06896
Epoch: 0150 train_loss= 0.70240 train_acc= 0.97143 val_loss= 1.13023 val_acc= 0.78000 time= 0.06996
Epoch: 0151 train_loss= 0.64483 train_acc= 0.95000 val_loss= 1.12727 val_acc= 0.78000 time= 0.06896
Epoch: 0152 train_loss= 0.64050 train_acc= 0.97143 val_loss= 1.12446 val_acc= 0.78000 time= 0.06796
Epoch: 0153 train_loss= 0.71223 train_acc= 0.95714 val_loss= 1.12179 val_acc= 0.78000 time= 0.06896
Epoch: 0154 train_loss= 0.68286 train_acc= 0.98571 val_loss= 1.11875 val_acc= 0.78000 time= 0.06896
Epoch: 0155 train_loss= 0.70416 train_acc= 0.95714 val_loss= 1.11599 val_acc= 0.78000 time= 0.06896
Epoch: 0156 train_loss= 0.71902 train_acc= 0.97143 val_loss= 1.11415 val_acc= 0.77800 time= 0.06896
Epoch: 0157 train_loss= 0.67448 train_acc= 0.97857 val_loss= 1.11215 val_acc= 0.77800 time= 0.06796
Epoch: 0158 train_loss= 0.66449 train_acc= 0.95714 val_loss= 1.11017 val_acc= 0.78000 time= 0.06896
Epoch: 0159 train_loss= 0.64438 train_acc= 0.96429 val_loss= 1.10892 val_acc= 0.78000 time= 0.06896
Epoch: 0160 train_loss= 0.64329 train_acc= 0.97143 val_loss= 1.10770 val_acc= 0.78200 time= 0.06896
Epoch: 0161 train_loss= 0.68548 train_acc= 0.97857 val_loss= 1.10604 val_acc= 0.78000 time= 0.07096
Epoch: 0162 train_loss= 0.67061 train_acc= 0.95000 val_loss= 1.10408 val_acc= 0.78000 time= 0.06896
Epoch: 0163 train_loss= 0.63683 train_acc= 0.97143 val_loss= 1.10300 val_acc= 0.78200 time= 0.06996
Epoch: 0164 train_loss= 0.66205 train_acc= 0.93571 val_loss= 1.10241 val_acc= 0.78000 time= 0.06996
Epoch: 0165 train_loss= 0.65909 train_acc= 0.97857 val_loss= 1.10189 val_acc= 0.77800 time= 0.06896
Epoch: 0166 train_loss= 0.65230 train_acc= 0.97857 val_loss= 1.10092 val_acc= 0.78000 time= 0.06896
Epoch: 0167 train_loss= 0.65994 train_acc= 0.94286 val_loss= 1.09960 val_acc= 0.78200 time= 0.06896
Epoch: 0168 train_loss= 0.68495 train_acc= 0.97143 val_loss= 1.09867 val_acc= 0.78200 time= 0.06996
Epoch: 0169 train_loss= 0.65944 train_acc= 0.97143 val_loss= 1.09731 val_acc= 0.78000 time= 0.06896
Epoch: 0170 train_loss= 0.66710 train_acc= 0.92857 val_loss= 1.09560 val_acc= 0.78000 time= 0.06796
Epoch: 0171 train_loss= 0.69614 train_acc= 0.95000 val_loss= 1.09331 val_acc= 0.78200 time= 0.06896
Epoch: 0172 train_loss= 0.65031 train_acc= 0.97857 val_loss= 1.09166 val_acc= 0.78200 time= 0.06796
Epoch: 0173 train_loss= 0.64674 train_acc= 0.95714 val_loss= 1.09022 val_acc= 0.78400 time= 0.06796
Epoch: 0174 train_loss= 0.58903 train_acc= 0.97857 val_loss= 1.08896 val_acc= 0.78200 time= 0.06896
Epoch: 0175 train_loss= 0.61592 train_acc= 0.96429 val_loss= 1.08718 val_acc= 0.78200 time= 0.06896
Epoch: 0176 train_loss= 0.67490 train_acc= 0.95714 val_loss= 1.08439 val_acc= 0.78400 time= 0.06896
Epoch: 0177 train_loss= 0.64824 train_acc= 0.98571 val_loss= 1.08142 val_acc= 0.78600 time= 0.06896
Epoch: 0178 train_loss= 0.60770 train_acc= 0.97857 val_loss= 1.07844 val_acc= 0.78400 time= 0.06896
Epoch: 0179 train_loss= 0.64699 train_acc= 0.95000 val_loss= 1.07634 val_acc= 0.78400 time= 0.06896
Epoch: 0180 train_loss= 0.66983 train_acc= 0.95000 val_loss= 1.07500 val_acc= 0.78600 time= 0.06896
Epoch: 0181 train_loss= 0.64909 train_acc= 0.96429 val_loss= 1.07334 val_acc= 0.78600 time= 0.06896
Epoch: 0182 train_loss= 0.60040 train_acc= 0.96429 val_loss= 1.07226 val_acc= 0.78600 time= 0.06896
Epoch: 0183 train_loss= 0.65879 train_acc= 0.95714 val_loss= 1.07135 val_acc= 0.78600 time= 0.06896
Epoch: 0184 train_loss= 0.64051 train_acc= 0.96429 val_loss= 1.07060 val_acc= 0.78600 time= 0.06996
Epoch: 0185 train_loss= 0.60902 train_acc= 0.96429 val_loss= 1.06962 val_acc= 0.78800 time= 0.06896
Epoch: 0186 train_loss= 0.63279 train_acc= 0.94286 val_loss= 1.06878 val_acc= 0.78800 time= 0.06996
Epoch: 0187 train_loss= 0.59645 train_acc= 0.98571 val_loss= 1.06733 val_acc= 0.78600 time= 0.06896
Epoch: 0188 train_loss= 0.63872 train_acc= 0.94286 val_loss= 1.06527 val_acc= 0.78600 time= 0.06796
Epoch: 0189 train_loss= 0.59015 train_acc= 0.97143 val_loss= 1.06310 val_acc= 0.78800 time= 0.06896
Epoch: 0190 train_loss= 0.56642 train_acc= 0.97143 val_loss= 1.06111 val_acc= 0.78800 time= 0.07296
Epoch: 0191 train_loss= 0.62657 train_acc= 0.95714 val_loss= 1.05898 val_acc= 0.78600 time= 0.06796
Epoch: 0192 train_loss= 0.64796 train_acc= 0.95000 val_loss= 1.05727 val_acc= 0.78800 time= 0.06896
Epoch: 0193 train_loss= 0.62399 train_acc= 0.97857 val_loss= 1.05572 val_acc= 0.78800 time= 0.06896
Epoch: 0194 train_loss= 0.61233 train_acc= 0.98571 val_loss= 1.05403 val_acc= 0.78600 time= 0.06896
Epoch: 0195 train_loss= 0.59135 train_acc= 0.97857 val_loss= 1.05217 val_acc= 0.78600 time= 0.06796
Epoch: 0196 train_loss= 0.64115 train_acc= 0.93571 val_loss= 1.05070 val_acc= 0.78800 time= 0.06896
Epoch: 0197 train_loss= 0.58866 train_acc= 0.95714 val_loss= 1.04922 val_acc= 0.78600 time= 0.06796
Epoch: 0198 train_loss= 0.59634 train_acc= 0.95714 val_loss= 1.04746 val_acc= 0.78600 time= 0.06796
Epoch: 0199 train_loss= 0.58434 train_acc= 0.98571 val_loss= 1.04561 val_acc= 0.78800 time= 0.06996
Epoch: 0200 train_loss= 0.61550 train_acc= 0.95714 val_loss= 1.04385 val_acc= 0.79000 time= 0.06696
Optimization Finished!
Test set results: cost= 1.00631 accuracy= 0.80900 time= 0.03098

(gcn) D:\code\Python\workplace\gcn\gcn>
